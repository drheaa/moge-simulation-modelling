\chapter{Simulation Study}

\section{Objective}

The real-data analysis in Chapter 6 showed that although first-goal timings in FIFA matches exhibited increasing hazard behaviour, the MOGE model performed poorly when applied to the observed dataset. Weibull and Gamma distributions fitted the data more accurately, while MOGE estimation was unstable and rejected by goodness-of-fit tests. This raises a key question: does MOGE inherently fail to represent football scoring, or was the small sample size and irregular scoring pattern insufficient for reliable EM estimation?

To answer this, simulation provides a controlled environment where true parameters are known. Synthetic observations generated from the MOGE distribution eliminate tactical variability and sample scarcity, allowing assessment of how well the EM algorithm recovers parameters under ideal conditions. If estimation improves with larger sample sizes, MOGE remains theoretically sound despite real-world challenges.

% ---------------------------------------------------------
\section{Simulation Setup and Methodology}

Synthetic i.i.d.\ samples were generated from the MOGE distribution with true parameters:
\[
(\alpha_0 = 1.5,\; \lambda_0 = 0.8,\; \theta_0 = 1.2),
\]
chosen to reflect moderately increasing hazard rates typical in early-match scoring.

Goal-time samples were simulated and parameter estimation repeated for increasing sample sizes:
\[
n \in \{30,\, 50,\, 100,\, 200\}.
\]

Multiple Monte-Carlo replications were conducted for each $n$. In each iteration, synthetic data was drawn from MOGE and the EM algorithm was used to re-estimate $(\alpha,\lambda,\theta)$. Recorded results enabled evaluation of estimator bias, MSE, variability and convergence.

This framework acts as a stress-test, examining how estimation accuracy improves with data volume and whether EM converges towards true values reliably.

% ---------------------------------------------------------
\section{Boxplots of Parameter Estimates}

\begin{figure}[h!]
\centering
\includegraphics[width=0.85\linewidth]{fig7_1_boxplot.png}
\caption{Boxplots of EM Parameter Estimates Across Sample Sizes}
\end{figure}

Boxplots illustrate parameter estimate distributions for each sample size. At $n=30$, estimates display wide variability, indicating high uncertainty. As the sample size increases to $n=50$ and $n=100$, dispersion narrows and medians approach true parameter values. By $n=200$, estimates become tightly clustered, demonstrating strong convergence and stability.

This supports that the MOGE estimator is highly sensitive to small samples but stabilises rapidly as data increases. Real-world data had only 29 points—insufficient for reliable EM performance—explaining the poor fitting observed in Chapter 6. Simulation confirms that the model itself is not flawed; rather, real data volume was inadequate.

% ---------------------------------------------------------
\section{Mean Squared Error (MSE) vs Sample Size}

\begin{figure}[h!]
\centering
\includegraphics[width=0.85\linewidth]{fig7_2_mse_plot.png}
\caption{Mean Squared Error of EM Parameter Estimates vs Sample Size}
\end{figure}

Mean Bias and MSE were computed for each parameter. Both metrics decrease consistently as $n$ increases. At low sample counts, estimates show mild positive bias, reflecting estimator uncertainty. With higher $n$, both bias and MSE reduce sharply, indicating improved accuracy and statistical reliability.

The decreasing MSE trend confirms the EM estimator is asymptotically consistent for MOGE. Combined with shrinking boxplot widths, the results validate that estimator precision strengthens significantly with data availability.

% ---------------------------------------------------------
\section{Convergence Behaviour of the EM Algorithm}

\begin{figure}[h!]
\centering
\includegraphics[width=0.85\linewidth]{fig7_3_convergence.png}
\caption{EM Algorithm Convergence (Simulated Sample, $n = 100$)}
\end{figure}

Convergence behaviour was assessed by tracking log-likelihood across EM iterations using a synthetic dataset of size $n=100$. As expected, likelihood increased after the first update step, consistent with EM theory guaranteeing monotonic improvement.

Although the displayed trace represents the initial update, full simulations (not shown for brevity) continued increasing until stabilisation. The absence of oscillation or divergence confirms smooth convergence under adequate sample size.

This indicates EM is computationally efficient and effective when data is sufficient. In contrast, real-match instability stemmed from limited observations—not algorithmic weakness. Under synthetic conditions, EM reliably improves likelihood, reinforcing findings from bias and MSE trends.

% ---------------------------------------------------------
\section{Bootstrapping for Parameter Stability}

To assess reliability of parameter estimates under real sample size constraints, a non-parametric bootstrap procedure was performed. A total of 300 bootstrap samples were drawn (with replacement) from home $(X_1)$ and away $(X_2)$ datasets. For each sample, MOGE parameters were re-estimated using EM and values stored.

Bootstrap results revealed considerable variability in parameters, especially for the away team. Away distributions showed heavier tails and greater dispersion, indicating more irregular scoring behaviour. Boxplots confirmed large confidence intervals, showing high uncertainty under limited data.

These results match simulation outcomes—small $n$ leads to parameter instability. Larger seasonal datasets would be required for narrow confidence bounds, improved reliability and inferential accuracy.

\begin{figure}[h!]
\centering
\includegraphics[width=0.85\linewidth]{fig7_4_boot_hist.png}
\caption{Bootstrap Histograms for $\alpha,\lambda,\theta$ (Home vs Away)}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.75\linewidth]{fig7_5_boot_box.png}
\caption{Bootstrap Parameter Variability Comparison: Home vs Away}
\end{figure}

% ---------------------------------------------------------
\section{Scatter Plot Analysis for Dependency Assessment}

To evaluate interaction between scoring processes, paired observations $(X_1,X_2)$ were plotted. The objective was to check whether the timing of one team's first goal influences the timing of the other.

\begin{figure}[h!]
\centering
\includegraphics[width=0.7\linewidth]{fig7_6_scatter.png}
\caption{Scatter Plot of Home vs Away First-Goal Times}
\end{figure}

Scatter results show no visible pattern or linear trend. Points remain widely scattered. Correlation coefficients:

\[
\text{Pearson}=-0.0376,\qquad 
\text{Spearman}=-0.0992,\qquad
\text{Kendall}=-0.0695
\]

All values are near zero and slightly negative, confirming negligible dependence. Home and away scoring processes operate independently with respect to timing. This validates separate marginal modelling without requiring a bivariate extension.

% ---------------------------------------------------------
\section{Conclusion}

This simulation study assessed theoretical performance of MOGE by generating synthetic data from known parameters and applying the EM estimator. Unlike real match data, where MOGE struggled due to sample limitations and scoring randomness, simulated results revealed strong estimator behaviour.

Parameter estimates converged toward true values as sample size increased. Bias and MSE decreased steadily across $n=30,50,100,200$. Convergence curves confirmed monotonic likelihood improvement, and bootstrap variability reflected the influence of data scarcity.

When data is generated from MOGE, the model outperforms Weibull, Gamma and Exponential distributions—opposite to real-world results—demonstrating that MOGE is theoretically robust. The challenge lies not in the model but in real dataset size.

In summary, MOGE is promising for football scoring analytics when applied to sufficiently large datasets or multi-season observations. Simulation results indicate strong potential for predictive modelling when data availability is expanded.

